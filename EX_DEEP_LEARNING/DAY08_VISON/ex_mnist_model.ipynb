{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ ì†ê¸€ì”¨ ìˆ«ì ì¸ì‹ ëª¨ë¸ êµ¬í˜„ ]\n",
    "- ë°ì´í„°ì…‹ : mnist_train.csv, mnist_test.csv\n",
    "- í•™ìŠµì¢…ë¥˜ : ì§€ë™í•™ìŠµ - ë‹¤ì¤‘í´ë˜ìŠ¤ë¶„ë¥˜\n",
    "- í•™ìŠµë°©ë²• : ì¸ê³µì‹ ê²½ë§ê¸°ë°˜ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] ëª¨ë“ˆë¡œë”© ë° ë°ì´í„° ì¤€ë¹„<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1-1] ëª¨ë“ˆë¡œë”©\n",
    "import sys\n",
    "sys.path.append('../Utils')\n",
    "import utils as uf                                      # í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "import torch                                            # í…ì„œ ë° ìˆ˜ì¹˜ê³¼í•™ í•¨ìˆ˜ë“¤ ê´€ë ¨ ëª¨ë“ˆ\n",
    "import torch.nn as nn                                   # ì‹ ê²½ë§ ì¸µ ê´€ë ¨ ëª¨ë“ˆ\n",
    "import torch.nn.functional as F                         # ì‹ ê²½ë§ í•¨ìˆ˜ë“¤(AF, LF, MF) ëª¨ë“ˆ\n",
    "import torch.optim as optim                             # ì‹ ê²½ë§ ìµœì í™” ëª¨ë“ˆ\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader        # pytorchì˜ ë°ì´í„° ë¡œë”©\n",
    "from torch.utils.data import Subset                     # pytorchì˜ ë°ì´í„°ì…‹ ê´€ë ¨ ëª¨ë“ˆ\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1-2] ë°ì´í„° ì¤€ë¹„\n",
    "TRAIN_FILE = '../Data/mnist_train.csv'\n",
    "TEST_FILE  = '../Data/mnist_test.csv'\n",
    "\n",
    "## [1-3] ë°ì´í„° ë¡œë”©\n",
    "trainDF = pd.read_csv(TRAIN_FILE, header=None)\n",
    "testDF  = pd.read_csv(TEST_FILE, header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¤€ë¹„ <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --------------------------------------------------------------------------------\n",
    "## [2-1] ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "## --------------------------------------------------------------------------------\n",
    "## í´ë˜ìŠ¤ì´ë¦„ : ClfDataset\n",
    "## ë¶€ëª¨í´ë˜ìŠ¤ : Dataset\n",
    "## ì˜¤ë²„ë¼ì´ë”© : _ _init_ _(self)        : [í•„ìˆ˜] í”¼ì³, íƒ€ê²Ÿ, [ì„ íƒ]í–‰ìˆ˜, ì»¬ëŸ¼ìˆ˜, íƒ€ê²Ÿ ìˆ˜...\n",
    "##            _ _len_ _(self)          : len() ë‚´ì¥í•¨ìˆ˜ ì‹¤í–‰ ì‹œ ìë™ í˜¸ì¶œ, ìƒ˜í”Œ ìˆ˜ ë°˜í™˜\n",
    "##            _ _getitem_ _(self, idx) : ì¸ìŠ¤í„´ìŠ¤ëª…[idx] ì‹œ ìë™ í˜¸ì¶œ,\n",
    "##                                       idxì— í•´ë‹¹í•˜ëŠ” í”¼ì³, íƒ€ê²Ÿì„ í…ì„œí™” í•´ì„œ ë°˜í™˜\n",
    "## --------------------------------------------------------------------------------\n",
    "class ClfDataset(Dataset):\n",
    "\n",
    "    ##- í”¼ì³ì™€ íƒ€ê²Ÿ ì €ì¥ ë° ê¸°íƒ€ ì†ì„± ì´ˆê¸°í™” \n",
    "    def __init__(self, dataDF):\n",
    "        super().__init__()\n",
    "        ## í”¼ì³, íƒ€ê²Ÿ ì´ˆê¸°í™” í•„ìˆ˜\n",
    "        self.x = dataDF[dataDF.columns[1:]].values\n",
    "        self.y = dataDF[dataDF.columns[0]].values\n",
    "\n",
    "\n",
    "    ##- ë°ì´í„° ìƒ˜í”Œ ìˆ˜ ë°˜í™˜ ë©”ì„œë“œ : len() í•¨ìˆ˜ì— ìë™í˜¸ì¶œë¨\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0] \n",
    "    \n",
    "    ##- ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” í”¼ì³ì™€ íƒ€ê²Ÿ í…ì„œ ë°˜í™˜ ë©”ì„œë“œ : ì¸ìŠ¤í„´ìŠ¤ëª…[index]ì— ìë™í˜¸ì¶œë¨\n",
    "    def __getitem__(self, index):\n",
    "        xTS = torch.tensor(self.x[index], dtype=torch.float32)\n",
    "        xTS = xTS.view(1, 28, 28)\n",
    "        xTS = xTS / 255.0 ## ì •ê·œí™”\n",
    "        \n",
    "        yTS = torch.tensor(self.y[index], dtype=torch.long)\n",
    "        return xTS, yTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allDS : 60000,  testDS : 10000\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "## --------------------------------------------------------------------------------\n",
    "## [2-2] ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì‚¬ìš©\n",
    "## --------------------------------------------------------------------------------\n",
    "allDS   = ClfDataset(trainDF)\n",
    "testDS  = ClfDataset(testDF)\n",
    "\n",
    "print(f'allDS : {len(allDS)},  testDS : {len(testDS)}')\n",
    "print(testDS[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = testDS[0][0].reshape(-1, 28)\n",
    "a2.unsqueeze_(0).shape\n",
    "a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [2-3] í•™ìŠµìš©/ê²€ì¦ìš©/í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ ë¶„ë¦¬\n",
    "\n",
    "## í•™ìŠµìš© ë°ì´í„°ì…‹ì—ì„œ íƒ€ê²Ÿ/ë¼ë²¨ë§Œ ì¶”ì¶œ \n",
    "targetList = allDS.y \n",
    "dataIndexList =list( range(len(allDS)))\n",
    "\n",
    "## í•™ìŠµìš©/ê²€ì¦ìš© ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ ë¶„ë¦¬\n",
    "## -train_test_split() í•¨ìˆ˜ : train:test = 75:25 ë¹„ìœ¨ë¡œ í•™ìŠµìš©, í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ ë¶„ë¦¬\n",
    "##                            stratify : ë¶„ë¥˜ìš© ë°ì´í„°ì…‹ ê²½ìš° ì¹´í…Œê³ ë¦¬ ë¹„ìœ¨ ìœ ì§€í•´ì„œ\n",
    "##                                       ë°ì´í„°ì…‹ ë¶„ë¦¬\n",
    "X_trainIdx, X_validIdx , y_train, y_valid = train_test_split( dataIndexList,\n",
    "                                                              targetList,\n",
    "                                                              train_size=0.8,\n",
    "                                                              stratify=targetList,\n",
    "                                                              random_state=10 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allDS   : <class '__main__.ClfDataset'>,   60000ê°œ\n",
      "trainDS : <class 'torch.utils.data.dataset.Subset'>, 48000ê°œ\n",
      "validDS : <class 'torch.utils.data.dataset.Subset'>, 12000ê°œ\n"
     ]
    }
   ],
   "source": [
    "## -----------------------------------------------------------------\n",
    "## í•™ìŠµìš©/ê²€ì¦ìš© ë°ì´í„°ì…‹ ìƒì„± ===> Dataset ==> 2ê°œ Subset ë¶„ë¦¬\n",
    "## -----------------------------------------------------------------\n",
    "trainDS = Subset(allDS, X_trainIdx)\n",
    "validDS = Subset(allDS, X_validIdx)\n",
    "\n",
    "print(f'allDS   : {type(allDS)},   {len(allDS)}ê°œ')\n",
    "print(f'trainDS : {type(trainDS)}, {len(trainDS)}ê°œ')\n",
    "print(f'validDS : {type(validDS)}, {len(validDS)}ê°œ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] ëª¨ë¸ í´ë˜ìŠ¤ ë§Œë“¤ê¸° <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --------------------------------------------------------------------\n",
    "## [3-1] ì»¤ìŠ¤í…€ ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜\n",
    "## --------------------------------------------------------------------\n",
    "##                 ì…ë ¥             ì»¤ë„      íŒ¨ë”©    ìŠ¤íŠ¸ë¼ì´ë“œ         ì¶œë ¥            í™œì„±í™” í•¨ìˆ˜\n",
    "## ì…ë ¥ì¸µ      (BS,1,28,28)          -         -         -         (BS,1,28,28)           -\n",
    "## Conv       (BS,1,28,28)        (3x3)10     -       (1,1)       (BS,10,26,26)         relu\n",
    "## Pool       (BS,1,28,28)        (2x2)1      -       (2,2)       (BS,10,13,13)          -\n",
    "## flatten    (BS,10,13,13)         -         -         -         (BS,10x13x13)          -\n",
    "## ì¶œë ¥ì¸µ      (BS,10x13x13)       í¼ì…‰íŠ¸ë¡ 10   -         -          (BS,10)            lossFNë”°ë¼\n",
    "## --------------------------------------------------------------------\n",
    "## í´ë˜ìŠ¤ì´ë¦„ : MNISTModel\n",
    "## ë¶€ëª¨í´ë˜ìŠ¤ : nn.Module\n",
    "## ì˜¤ë²„ë¼ì´ë”© : __init__(self)\n",
    "##            forward(self, x)\n",
    "## \n",
    "## --------------------------------------------------------------------\n",
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_layer = nn.Conv2d(1, 10, 3)    ## í‘ë°±, ì»¤ë„ 10ê°œ. ì»¤ë„ 3*3, ìŠ¤íŠ¸ë¼ì´ë“œ 1, íŒ¨ë”© x\n",
    "        self.pool_layer = nn.MaxPool2d(2, 2)     ## Downsampling í¬ê¸° ì¦‰, í–‰ê³¼ ì—´ 1/2 ì¤„ì„\n",
    "        self.flatten_layer = nn.Flatten()        ## 4D(BS, C, H, W) -> 2D (BS, C*H*W)\n",
    "        self.out_layer = nn.Linear(1690, 10)     ## (C*H*W, 10) \n",
    "    \n",
    "    ## ìˆœë°©í–¥ í•™ìŠµ ì§„í–‰ í•¨ìˆ˜\n",
    "    def forward(self, x) :\n",
    "        # - data ì…ë ¥ì¸µ -> ì€ë‹‰ì¸µ 1 : conv2d\n",
    "        out = F.relu(self.conv_layer(x))\n",
    "        \n",
    "        # - ì€ë‹‰ì¸µ 2 : MaxPooling2D\n",
    "        out = self.pool_layer(out)\n",
    "        \n",
    "        #- ì€ë‹‰ì¸µ 3 : Flatten\n",
    "        out = self.flatten_layer(out)         \n",
    "        \n",
    "        #- ì¶œë ¥ì¸µ \n",
    "        out = self.out_layer(out)\n",
    "        return out    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MNISTModel                               [1, 10]                   --\n",
       "â”œâ”€Conv2d: 1-1                            [1, 10, 26, 26]           100\n",
       "â”œâ”€MaxPool2d: 1-2                         [1, 10, 13, 13]           --\n",
       "â”œâ”€Flatten: 1-3                           [1, 1690]                 --\n",
       "â”œâ”€Linear: 1-4                            [1, 10]                   16,910\n",
       "==========================================================================================\n",
       "Total params: 17,010\n",
       "Trainable params: 17,010\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.08\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.07\n",
       "Estimated Total Size (MB): 0.13\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## --------------------------------------------------------------------\n",
    "## [3-2] ì»¤ìŠ¤í…€ ëª¨ë¸ í´ë˜ìŠ¤ êµ¬ì¡° í™•ì¸ -> torchinfo í™œìš©\n",
    "## --------------------------------------------------------------------\n",
    "from torchinfo import summary\n",
    "\n",
    "model = MNISTModel()\n",
    "summary(model, input_size = (1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTModel(\n",
       "  (conv_layer): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten_layer): Flatten(start_dim=1, end_dim=-1)\n",
       "  (out_layer): Linear(in_features=1690, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNISTModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] í•™ìŠµ ì¤€ë¹„ <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------------------------------------------------\n",
    "## [4-1] í•™ìŠµ ê´€ë ¨ ì„¤ì •\n",
    "## ------------------------------------------------------------\n",
    "## í•™ìŠµ ì§„í–‰ íšŸìˆ˜ ë° í•™ìŠµëŸ‰, í•™ìŠµ ì§„í–‰ ìœ„ì¹˜, W/b ì—…ë°ì´íŠ¸ ê°„ê²©\n",
    "EPOCHS      = 100\n",
    "BATCH_SIZE  = 200\n",
    "LR          = 0.01\n",
    "DEVICE      = 'cuda' if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------------------------------------------------\n",
    "## [4-2] í•™ìŠµ ê´€ë ¨ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "## ------------------------------------------------------------\n",
    "## -> Model ì¸ìŠ¤í„´ìŠ¤ : ìë™ìœ¼ë¡œ ì¸µë³„ W, b í…ì„œ ìƒì„± ë° ëœë¤ ì´ˆê¸°í™”\n",
    "model = MNISTModel().to(DEVICE)\n",
    "\n",
    "## -> ì†ì‹¤í•¨ìˆ˜ ì¸ìŠ¤í„´ìŠ¤ : ë‹¤ì¤‘ë¶„ë¥˜ìš©\n",
    "lossFn = nn.CrossEntropyLoss()\n",
    "\n",
    "## -> ìµœì í™” ì¸ìŠ¤í„´ìŠ¤ : ëª¨ë¸ì˜ ì¸µë³„ íŒŒë¼ë¯¸í„° ì¦‰, W, b ì—…ë°ì´íŠ¸\n",
    "optim = optim.Adam(model.parameters(), lr= LR)\n",
    "\n",
    "## -> ë°ì´í„°ë¡œë” ì¸ìŠ¤í„´ìŠ¤ : í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©ë  í•™ìŠµëŸ‰ ë§Œí¼ ë°ì´í„° ì¶”ì¶œ\n",
    "trainDL = DataLoader(trainDS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validDL = DataLoader(validDS, batch_size=BATCH_SIZE)\n",
    "testDL = DataLoader(testDS, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] í•™ìŠµ ì§„í–‰ <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "patience = 10\n",
    "min_delta = 1e-4\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "wait = 0\n",
    "best_state_dict = None\n",
    "best_epoch = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH - 000] TRAIN => Loss : 0.3371094   Acc : 0.90129\n",
      "              VALID=> Loss : 0.1474394   Acc : 0.95483\n",
      "[EPOCH - 001] TRAIN => Loss : 0.1101117   Acc : 0.96854\n",
      "              VALID=> Loss : 0.0914086   Acc : 0.97208\n",
      "[EPOCH - 002] TRAIN => Loss : 0.0820413   Acc : 0.97535\n",
      "              VALID=> Loss : 0.0863746   Acc : 0.97267\n",
      "[EPOCH - 003] TRAIN => Loss : 0.0679215   Acc : 0.97960\n",
      "              VALID=> Loss : 0.0764853   Acc : 0.97675\n",
      "[EPOCH - 004] TRAIN => Loss : 0.0563177   Acc : 0.98227\n",
      "              VALID=> Loss : 0.0757359   Acc : 0.97625\n",
      "[EPOCH - 005] TRAIN => Loss : 0.0542643   Acc : 0.98315\n",
      "              VALID=> Loss : 0.0723843   Acc : 0.97750\n",
      "[EPOCH - 006] TRAIN => Loss : 0.0467668   Acc : 0.98460\n",
      "              VALID=> Loss : 0.0702444   Acc : 0.97917\n",
      "[EPOCH - 007] TRAIN => Loss : 0.0410356   Acc : 0.98650\n",
      "              VALID=> Loss : 0.0738995   Acc : 0.97900\n",
      "â³ No improvement. wait=1/10\n",
      "[EPOCH - 008] TRAIN => Loss : 0.0401446   Acc : 0.98752\n",
      "              VALID=> Loss : 0.0820157   Acc : 0.97717\n",
      "â³ No improvement. wait=2/10\n",
      "[EPOCH - 009] TRAIN => Loss : 0.0333411   Acc : 0.98896\n",
      "              VALID=> Loss : 0.0732249   Acc : 0.97925\n",
      "â³ No improvement. wait=3/10\n",
      "[EPOCH - 010] TRAIN => Loss : 0.0297057   Acc : 0.99015\n",
      "              VALID=> Loss : 0.0819799   Acc : 0.97825\n",
      "â³ No improvement. wait=4/10\n",
      "[EPOCH - 011] TRAIN => Loss : 0.0265997   Acc : 0.99104\n",
      "              VALID=> Loss : 0.0772045   Acc : 0.97825\n",
      "â³ No improvement. wait=5/10\n",
      "[EPOCH - 012] TRAIN => Loss : 0.0266011   Acc : 0.99129\n",
      "              VALID=> Loss : 0.0900171   Acc : 0.97783\n",
      "â³ No improvement. wait=6/10\n",
      "[EPOCH - 013] TRAIN => Loss : 0.0238733   Acc : 0.99208\n",
      "              VALID=> Loss : 0.0980915   Acc : 0.97467\n",
      "â³ No improvement. wait=7/10\n",
      "[EPOCH - 014] TRAIN => Loss : 0.0221889   Acc : 0.99250\n",
      "              VALID=> Loss : 0.0962855   Acc : 0.97833\n",
      "â³ No improvement. wait=8/10\n",
      "[EPOCH - 015] TRAIN => Loss : 0.0208739   Acc : 0.99290\n",
      "              VALID=> Loss : 0.1039920   Acc : 0.97508\n",
      "â³ No improvement. wait=9/10\n",
      "[EPOCH - 016] TRAIN => Loss : 0.0177373   Acc : 0.99406\n",
      "              VALID=> Loss : 0.0987684   Acc : 0.97742\n",
      "â³ No improvement. wait=10/10\n",
      "ğŸ›‘ Early stopping! best_epoch=6, best_valid_loss=0.070244\n"
     ]
    }
   ],
   "source": [
    "### --> í•™ìŠµ ì§„í–‰\n",
    "## - í•™ìŠµê³¼ ê²€ì¦ ê²°ê³¼ ì €ì¥ : í•™ìŠµ ì§„í–‰/ì¤‘ë‹¨ ì—¬ë¶€ ê²°ì •, ëª¨ë¸ ì €ì¥ ì—¬ë¶€\n",
    "TRAIN_LA = {'loss' : [] , 'acc' : []}\n",
    "VALID_LA = {'loss' : [] , 'acc' : []}\n",
    "\n",
    "## ì§€ì •ëœ í•™ìŠµ íšŸìˆ˜ ë§Œí¼ í•™ìŠµ ì§„í–‰ & ì—í¬í¬ ë‹¨ìœ„ë¡œ í•™ìŠµê³¼ ê²€ì¦ ê²°ê³¼ ì €ì¥\n",
    "for epoch in range(EPOCHS):\n",
    "    ## 1 ì—í¬í¬ í•™ìŠµ\n",
    "    train_loss, train_acc = uf.train_one_epoch(model, trainDL, lossFn, optim, DEVICE)\n",
    "    \n",
    "    ## 1ì—í¬í¬ í•™ìŠµ í›„ ì—…ë°ì´íŠ¸ W, b ê²€ì‚¬ : í•™ìŠµì— ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ë°ì´í„°\n",
    "    valid_loss, valid_acc = uf.evaluate(model, validDL, lossFn, DEVICE)\n",
    "    \n",
    "    ## í•™ìŠµê³¼ ê²€ì¦ ê²°ê³¼ ì €ì¥\n",
    "    TRAIN_LA['loss'].append(train_loss)\n",
    "    TRAIN_LA['acc'].append(train_acc)\n",
    "    VALID_LA['loss'].append(valid_loss)\n",
    "    VALID_LA['acc'].append(valid_acc)\n",
    "    \n",
    "    ## ì§„í–‰ ìƒí™© ì¶œë ¥\n",
    "    print(f'[EPOCH - {epoch:03}] TRAIN => Loss : {train_loss:.7f}   Acc : {train_acc:.5f}')\n",
    "    print(f'{\" \"*14}VALID=> Loss : {valid_loss:.7f}   Acc : {valid_acc:.5f}')\n",
    "    \n",
    "     # 3) Early Stopping (ifë¬¸)\n",
    "    # ê°œì„  ì¡°ê±´: valid_lossê°€ bestë³´ë‹¤ min_delta ì´ìƒ ê°ì†Œ\n",
    "    if valid_loss < best_valid_loss - min_delta:\n",
    "        best_valid_loss = valid_loss\n",
    "        wait = 0\n",
    "        best_epoch = epoch\n",
    "\n",
    "        # best ëª¨ë¸ ì €ì¥(ë©”ëª¨ë¦¬)\n",
    "        best_state_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    else:\n",
    "        wait += 1\n",
    "        print(f'ì¦ê°€ ì—†ìŒ {wait}/{patience}')\n",
    "\n",
    "        if wait >= patience:\n",
    "            print(f'ë©ˆì¶¤! best_epoch={best_epoch}, best_valid_loss={best_valid_loss:.6f}')\n",
    "            break\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch251",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

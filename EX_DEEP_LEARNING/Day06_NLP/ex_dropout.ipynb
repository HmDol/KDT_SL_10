{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de211452",
   "metadata": {},
   "source": [
    "#### [규제 layer - Dropout]\n",
    "- 모델의 과대적합을 위한 규제 중\n",
    "- 출력값에 지정된 비율(p)만큼 0으로 처리해 주는 층"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957bd620",
   "metadata": {},
   "source": [
    "[1] 모듈로딩 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "709b198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모듈로딩\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bff20a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0421, -1.4802,  2.2489, -0.7557],\n",
      "        [ 0.0620, -0.5880, -0.5099,  1.1585]])\n"
     ]
    }
   ],
   "source": [
    "## 2개 layer 생성\n",
    "fcLay = nn.Linear(4, 4)\n",
    "dropLay = nn.Dropout(p=0.5)\n",
    "\n",
    "##- 테스트용 텐서 생성\n",
    "x = torch.randn(2,4)\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af23ec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zTS ==>\n",
      "tensor([[-1.6351,  1.2303, -0.2550, -0.5781],\n",
      "        [-0.3863, -0.2201,  0.2665,  0.0110]], grad_fn=<AddmmBackward0>) \n",
      "\n",
      " aTS===>\n",
      "tensor([[0.0000, 1.2303, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2665, 0.0110]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## 가중합 계산 + 활성화 함수\n",
    "zTS = fcLay(x)\n",
    "aTS = torch.relu(zTS)\n",
    "\n",
    "print(f'zTS ==>\\n{zTS} \\n\\n aTS===>\\n{aTS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd285112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aTS ==>\n",
      "tensor([[0.0000, 1.2303, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2665, 0.0110]], grad_fn=<ReluBackward0>) \n",
      "\n",
      " outTS===>\n",
      "tensor([[0.0000, 2.4605, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0220]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## [규제 Dropout] ---------------------------\n",
    "## 일부 출력값 0 처리\n",
    "## w도 없고, b도 없음\n",
    "## 선형결과 (가중합)을 절대 하지 않음\n",
    "## 이미 계산된 activation에 마스크만 곱함\n",
    "## -----------------------------------------\n",
    "outTS = dropLay(aTS)\n",
    "print(f'aTS ==>\\n{aTS} \\n\\n outTS===>\\n{outTS}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b98eff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask\n",
      "tensor([[0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1.]])\n",
      "outTs\n",
      "tensor([[0.0000, 1.5378, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3331, 0.0137]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## ----------------------------------\n",
    "## 학습중 :\n",
    "## ----------------------------------\n",
    "\n",
    "p = 0.2\n",
    "mask = (torch.rand_like(aTS) > p).float()\n",
    "\n",
    "print(f'mask\\n{mask}')\n",
    "\n",
    "outTS = aTS * mask / (1-p)\n",
    "print(f'outTs\\n{outTS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -----------------------\n",
    "## 평가시 : 입력받은 tensor 그대로 출력\n",
    "## -----------------------\n",
    "outTS = aTS ## 아무것도 안함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e5c325",
   "metadata": {},
   "source": [
    "#### 【 안정화 Layer - BachNormLayer 】 <hr>\n",
    "\n",
    "- 문제 상황\n",
    "    * 신경망에서 한 층의 출력 분포가 계속 변함.\n",
    "    * 가중치 업데이트 → 다음 층 입력 분포 변화 → 학습 불안정, 느린 수렴\n",
    "    * Internal Covariate Shift 설명함\n",
    "\n",
    "- 해결 방안\n",
    "    * 미니배치 단위로 평균과 분산 맞추어 각 층의 입력 분포를 안정화\n",
    "    * 평균 0, 분산 1 데이터 위치 변경 ==> 선형 변환(affine transform) \n",
    "        - 값들의 순서 유지\n",
    "        - 상대적 거리 비율 유지\n",
    "        - 정보 보존\n",
    "- 효과\n",
    "    * 기울기가 안정적으로 흐름\n",
    "    * 활성함수가 가장 잘 작동\n",
    "    * 학습이 빠르고 안정적\n",
    "        \n",
    "- 순서\n",
    "    1. 미니배치 평균\n",
    "    2. 미니배치 분산\n",
    "    3. 정규화\n",
    "    4. 학습 가능한 복원 => 정규화 후에도 표현력 유지 위함\n",
    "        - γ (gamma) : scale - 얼마나 강조할지\n",
    "        - β (beta) : shift - 어디로 이동시킬지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6eff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##- 모듈 로딩\n",
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1349869e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27.4549, 37.7202, 68.5586],\n",
      "        [45.6194, 64.4580, 35.1747],\n",
      "        [56.5999, 34.8713, 52.5918],\n",
      "        [37.1012, 42.8687, 52.3761]])\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------\n",
    "## BatchNorm 없이\n",
    "## ---------------------------------------------------\n",
    "x = torch.randn(4, 3) * 10 + 50  \n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af40492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 평균: tensor([41.6939, 44.9796, 52.1753])\n",
      "입력 분산: tensor([115.3606, 134.6853, 139.4121])\n",
      "------------------------------------------------------------\n",
      "출력 평균: tensor([ 3.7253e-08, -7.8231e-08, -9.4529e-08])\n",
      "출력 분산: tensor([1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "##- eps : 입실론(epsilon, ε)\n",
    "##-       분산이 0에 가까울 때\n",
    "##-       나눗셈이 폭주하거나 NaN이 되는 것을 막기 위한\n",
    "##-       아주 작은 안정화 상수\n",
    "eps = 1e-5\n",
    "\n",
    "# 1) batch 통계\n",
    "mean = x.mean(dim=0)\n",
    "var  = x.var(dim=0, unbiased=False)\n",
    "\n",
    "# 2) 정규화\n",
    "x_hat = (x - mean) / torch.sqrt(var + eps)\n",
    "\n",
    "# 3) 학습 파라미터\n",
    "gamma = torch.ones(3)\n",
    "beta  = torch.zeros(3)\n",
    "\n",
    "y = gamma * x_hat + beta\n",
    "\n",
    "# 4) 변화된 평균/분산\n",
    "print(\"입력 평균:\", x.mean(dim=0))\n",
    "print(\"입력 분산:\", x.var(dim=0, unbiased=False))\n",
    "print(\"-\"*60)\n",
    "print(\"출력 평균:\", y.mean(dim=0))\n",
    "print(\"출력 분산:\", y.var(dim=0, unbiased=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95515db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 평균 :  tensor([ 5.9605e-08, -5.9605e-08, -5.9605e-08], grad_fn=<MeanBackward1>)\n",
      "입력 분산 :  tensor([1.0000, 1.0000, 1.0000], grad_fn=<VarBackward0>)\n",
      "출력 평균: tensor([0.0000e+00, 0.0000e+00, 3.5763e-07], grad_fn=<MeanBackward1>)\n",
      "출력 분산: tensor([1.0000, 1.0000, 1.0000], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------\n",
    "## BatchNorm1d 사용\n",
    "## ---------------------------------------------------\n",
    "## 테스트 데이터\n",
    "x=torch.randn(4,3) * 10 + 50\n",
    "\n",
    "##- 인스턴스 생성\n",
    "bn = nn.BatchNorm1d(3)\n",
    "\n",
    "##- 훈련 모드 \n",
    "bn.train()   \n",
    "\n",
    "##- 배치 정규화 진행\n",
    "print(\"입력 평균 : \", y.mean(dim=0))\n",
    "print(\"입력 분산 : \", y.var(dim=0, unbiased=False))\n",
    "\n",
    "\n",
    "y = bn(x)\n",
    "\n",
    "print(\"출력 평균:\", y.mean(dim=0))\n",
    "print(\"출력 분산:\", y.var(dim=0, unbiased=False))\n",
    "\n",
    "## 내부에서 똑같은 계산 + γ, β 학습을 자동으로 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5f1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------------------------------------\n",
    "##          학습(train) vs 평가(eval) 차이 \n",
    "## -------------------------------------------------\n",
    "## [학습 시 ]\n",
    "## -> 현재 미니배치 평균/분산 사용\n",
    "## -> 동시에 running_mean, running_var 갱신\n",
    "\n",
    "## [평가 시 ]\n",
    "## -> running_mean, running_var만 사용\n",
    "## -> 배치 크기에 영향 없음\n",
    "\n",
    "bn.eval()    \n",
    "y_test = bn(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b531a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%pip install koreanize-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "239809d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'koreanize_matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkoreanize_matplotlib\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m## -----------------------------\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m## 재현성을 위한 시드 고정\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m## -----------------------------\u001b[39;00m\n\u001b[32m     11\u001b[39m torch.manual_seed(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'koreanize_matplotlib'"
     ]
    }
   ],
   "source": [
    "## -----------------------------\n",
    "## 모듈 로딩\n",
    "## -----------------------------\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "\n",
    "## -----------------------------\n",
    "## 재현성을 위한 시드 고정\n",
    "## -----------------------------\n",
    "torch.manual_seed(0)\n",
    "\n",
    "## -----------------------------\n",
    "## 1) BN 적용 전 입력 데이터 생성\n",
    "##    평균이 크고 분산이 큰 \n",
    "##    불안정한 분포를 일부러 만듦\n",
    "## -----------------------------\n",
    "N = 4096\n",
    "x = torch.randn(N) * 10 + 50   # 평균≈50, 표준편차≈10\n",
    "\n",
    "## -----------------------------\n",
    "## 2) BatchNorm의 정규화 단계\n",
    "##    (미니배치 평균, 분산 사용)\n",
    "## -----------------------------\n",
    "eps  = 1e-5                   # 수치 안정성을 위한 epsilon\n",
    "mean = x.mean()               # 배치 평균\n",
    "var  = x.var(unbiased=False)  # 배치 분산\n",
    "\n",
    "# 평균 0, 분산 1로 정규화\n",
    "x_hat = (x - mean) / torch.sqrt(var + eps)\n",
    "\n",
    "## -----------------------------\n",
    "## 3) BatchNorm의 affine 변환 (γ, β)\n",
    "##    → 필요하면 분포를 다시 이동/확대\n",
    "## -----------------------------\n",
    "gamma = torch.tensor(12.0)    # 스케일 파라미터 (학습 대상)\n",
    "beta  = torch.tensor(40.0)    # 시프트 파라미터 (학습 대상)\n",
    "\n",
    "y = gamma * x_hat + beta\n",
    "\n",
    "## -----------------------------\n",
    "## 통계 출력용 함수\n",
    "## -----------------------------\n",
    "def stats(t):\n",
    "    return float(t.mean()), float(t.std(unbiased=False)), float(t.var(unbiased=False))\n",
    "\n",
    "mx, sx, vx = stats(x)\n",
    "mh, sh, vh = stats(x_hat)\n",
    "my, sy, vy = stats(y)\n",
    "\n",
    "## -----------------------------\n",
    "## 4) BN 적용 전 분포 시각화\n",
    "## -----------------------------\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(x.numpy(), bins=60)\n",
    "plt.title(f\"BN 적용 전 (x)\\nmean={mx:.2f}, std={sx:.2f}\")\n",
    "plt.xlabel(\"값\")\n",
    "plt.ylabel(\"빈도\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## -----------------------------\n",
    "## 5) BN 정규화 후 분포 시각화\n",
    "## -----------------------------\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(x_hat.numpy(), bins=60)\n",
    "plt.title(f\"BN 정규화 후 (x_hat)\\nmean={mh:.2f}, std={sh:.2f}\")\n",
    "plt.xlabel(\"값\")\n",
    "plt.ylabel(\"빈도\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## -----------------------------\n",
    "## 6) γ, β 적용 후 분포 시각화\n",
    "## -----------------------------\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(y.numpy(), bins=60)\n",
    "plt.title(f\"BN affine 적용 후 (y)\\nmean={my:.2f}, std={sy:.2f}\")\n",
    "plt.xlabel(\"값\")\n",
    "plt.ylabel(\"빈도\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 7) 요약 통계 출력\n",
    "# -----------------------------\n",
    "print(\"분포 요약\")\n",
    "print(f\"BN 적용 전           : mean={mx:.4f}, var={vx:.4f}\")\n",
    "print(f\"BN 정규화 후 (x_hat) : mean={mh:.4f}, var={vh:.4f}\")\n",
    "print(f\"BN affine 후 (y)     : mean={my:.4f}, var={vy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eacc8c60",
   "metadata": {},
   "source": [
    "#### [0121 WORK 다변량 분류 모델]\n",
    "- 주제 : 숫자 분류\n",
    "- 데이터 : mnist_train.csv\n",
    "- 구성 : 피쳐 + 타겟\n",
    "- 학습 : 지도학습  + 분류\n",
    "- 구현 : 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e631a4fe",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f324fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb477029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10001 entries, 0 to 10000\n",
      "Columns: 785 entries, 0 to 784\n",
      "dtypes: int64(785)\n",
      "memory usage: 59.9 MB\n"
     ]
    }
   ],
   "source": [
    "data_file = \"../Data/mnist_train.csv\"\n",
    "\n",
    "dataDF = pd.read_csv(data_file, header=None)\n",
    "dataDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "304d6ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTS :  torch.Size([10001, 784]) <built-in method dim of Tensor object at 0x000001E1D04CE610> \n",
      "yTS :  torch.Size([10001]) <built-in method dim of Tensor object at 0x000001E1B8A39D00>\n"
     ]
    }
   ],
   "source": [
    "## 데이터 텐서 변환\n",
    "featureDF = dataDF.iloc[:, 1:].values\n",
    "xTS = torch.tensor(featureDF, dtype=torch.float32) / 255.0\n",
    "\n",
    "targetDF = dataDF.iloc[:, 0].values\n",
    "yTS = torch.tensor(targetDF, dtype=torch.long)\n",
    "\n",
    "print(\"xTS : \", xTS.shape,xTS.dim, \"\\nyTS : \", yTS.shape, yTS.dim )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf71590",
   "metadata": {},
   "source": [
    "[2] ann 모델 설계<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ==========================================================\n",
    "##          입력수      퍼셉트론수/출력수       AF\n",
    "## ==========================================================\n",
    "## 입력층     784            784          ★Pytorch에는 입력층(클래스) X, 입력 텐서를 입력층으로 간주\n",
    "## 은닉층     784            128              ReLU\n",
    "## 은닉층     128            64               ReLU\n",
    "## 출력층     64             10              softmax\n",
    "## ==========================================================\n",
    "## 클래스이름 : MnistModel\n",
    "## 부모클래스 : nn.Module\n",
    "## 오버라이딩 : __init__(self)  : 층 구성 요소 인스턴스 생성\n",
    "##            forward(self, x) : 순전파 진행 메서드, ★ x:입력층\n",
    "## ==========================================================\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hd1_layer = nn.Linear(784, 128)\n",
    "        self.hd2_layer = nn.Linear(128, 64)\n",
    "        self.out_layer = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hd1_layer(x))\n",
    "        x = F.relu(self.hd2_layer(x))\n",
    "        x = self.out_layer(x)   # CrossEntropyLoss()을 쓸경우 자동으로 SOFTMAX\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31bcecd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MnistModel                               [2, 10]                   --\n",
       "├─Linear: 1-1                            [2, 128]                  100,480\n",
       "├─Linear: 1-2                            [2, 64]                   8,256\n",
       "├─Linear: 1-3                            [2, 10]                   650\n",
       "==========================================================================================\n",
       "Total params: 109,386\n",
       "Trainable params: 109,386\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.22\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.44\n",
       "Estimated Total Size (MB): 0.45\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 모델 객체 생성\n",
    "model = MnistModel()\n",
    "summary(model, input_size=(2,784))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52bb17c",
   "metadata": {},
   "source": [
    "[3] 학습 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e4cb30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [3-1] 학습 관련 설정값들\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 200\n",
    "COUNT = xTS.shape[0] // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d278b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [3-2] 학습 관련 인스턴스들\n",
    "## -> 모델 인스턴스\n",
    "model = MnistModel()\n",
    "\n",
    "## -> 손실 계산 객체\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "## -> 최적화 인스턴스\n",
    "adamOpt = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d9b3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000] loss=1.3773, acc=0.8634\n",
      "[005] loss=0.2153, acc=0.9477\n",
      "[010] loss=0.1236, acc=0.9713\n",
      "[015] loss=0.0756, acc=0.9826\n",
      "[020] loss=0.0456, acc=0.9905\n",
      "[025] loss=0.0271, acc=0.9951\n",
      "[030] loss=0.0173, acc=0.9951\n",
      "[035] loss=0.0124, acc=0.9888\n",
      "[040] loss=0.0163, acc=0.9898\n",
      "[045] loss=0.0121, acc=0.9972\n",
      "[050] loss=0.0032, acc=0.9991\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS + 1):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for idx in range(COUNT):\n",
    "        xb = xTS[idx*BATCH_SIZE:(idx+1)*BATCH_SIZE]\n",
    "        yb = yTS[idx*BATCH_SIZE:(idx+1)*BATCH_SIZE]\n",
    "\n",
    "        logits = model(xb) ## 순전파 진행\n",
    "        loss = loss_fn(logits, yb)\n",
    "\n",
    "        adamOpt.zero_grad() ## 기울기 초기화\n",
    "        loss.backward()     ## 역전파 진행\n",
    "        adamOpt.step()      ## 가중치 업데이트 및 최적화\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            pred = model(xTS).argmax(dim=1)\n",
    "            acc = (pred == yTS).float().mean().item()\n",
    "        print(f\"[{epoch:03}] loss={total_loss/COUNT:.4f}, acc={acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch251",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8945f81e",
   "metadata": {},
   "source": [
    "#### [1] 데이터 준비\n",
    "- 데이터 정리 및 두 데이터셋 병합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1-1] 데이터 정리\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb3 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1067\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_tokens\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1227\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1240\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._string_convert\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1527\u001b[39m, in \u001b[36mpandas._libs.parsers._string_box_utf8\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xb3 in position 0: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./Data/human_made.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 필요한 컬럼만 남기기 (Unnamed 같은 쓰레기 컬럼 제거)\u001b[39;00m\n\u001b[32m      4\u001b[39m df = df[[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kdt008\\anaconda3\\envs\\NLP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:873\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    861\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    862\u001b[39m     dialect,\n\u001b[32m    863\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    870\u001b[39m )\n\u001b[32m    871\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kdt008\\anaconda3\\envs\\NLP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:306\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kdt008\\anaconda3\\envs\\NLP\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1947\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1940\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1941\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1942\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1943\u001b[39m     (\n\u001b[32m   1944\u001b[39m         index,\n\u001b[32m   1945\u001b[39m         columns,\n\u001b[32m   1946\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1947\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1949\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1950\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1951\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kdt008\\anaconda3\\envs\\NLP\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:215\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    217\u001b[39m         data = _concatenate_chunks(chunks, \u001b[38;5;28mself\u001b[39m.names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:832\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:911\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1009\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_column_data\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1078\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_tokens\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1227\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1240\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._string_convert\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1527\u001b[39m, in \u001b[36mpandas._libs.parsers._string_box_utf8\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xb3 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"./Data/human_made.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# 필요한 컬럼만 남기기 (Unnamed 같은 쓰레기 컬럼 제거)\n",
    "df = df[[\"id\", \"text\", \"label\"]]\n",
    "\n",
    "# 완전 빈 행 제거\n",
    "df = df.dropna(subset=[\"id\", \"text\", \"label\"])\n",
    "\n",
    "# 공백만 있는 행 제거\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df = df[df[\"text\"] != \"\"]\n",
    "\n",
    "# label 정수화\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "df.to_csv(\"./Data/human_made_clean.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364817d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"./Data/AI_made.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# 필요한 컬럼만 남기기 (Unnamed 같은 쓰레기 컬럼 제거)\n",
    "df = df[[\"id\", \"text\", \"label\"]]\n",
    "\n",
    "# 완전 빈 행 제거\n",
    "df = df.dropna(subset=[\"id\", \"text\", \"label\"])\n",
    "\n",
    "# 공백만 있는 행 제거\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df = df[df[\"text\"] != \"\"]\n",
    "\n",
    "# label 정수화\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "df.to_csv(\"./Data/AI_made_clean.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fcc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      30 non-null     float64\n",
      " 1   text    30 non-null     str    \n",
      " 2   label   30 non-null     int64  \n",
      "dtypes: float64(1), int64(1), str(1)\n",
      "memory usage: 852.0 bytes\n",
      "\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   id      30 non-null     int64\n",
      " 1   text    30 non-null     str  \n",
      " 2   label   30 non-null     int64\n",
      "dtypes: int64(2), str(1)\n",
      "memory usage: 852.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/human_made_clean.csv', encoding='utf-8')\n",
    "df.info()\n",
    "print()\n",
    "df = pd.read_csv('./Data/AI_made_clean.csv', encoding='utf-8')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0443b92",
   "metadata": {},
   "source": [
    "[1-2] 데이터 병합 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93573908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: ./Data/all.csv\n",
      "전체 샘플 수: 60\n",
      "라벨 분포:\n",
      " label\n",
      "0    30\n",
      "1    30\n",
      "Name: count, dtype: int64\n",
      "샘플 컬럼: ['new_id', 'id', 'text', 'label', 'source']\n",
      "   new_id   id                                               text  label  \\\n",
      "0       1  1.0  너도 나도 창의성, 발상의 전환이 필요하다고 외칩니다. 하지만 주구장창 발상의 전환...      0   \n",
      "1       2  2.0  다양한 현장을 넘나들고 취재한 경험을 통해 통합적 인재로 한발 나아갈 수 있었습니다...      0   \n",
      "2       3  3.0  전략적 소통\\n\\n소통은 끊임없이 벌어집니다. 선의를 가진 사람과 소통할 경우엔 문...      0   \n",
      "\n",
      "  source  \n",
      "0  human  \n",
      "1  human  \n",
      "2  human  \n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 설정: 입력/출력 경로\n",
    "# =========================\n",
    "HUMAN_PATH = \"./Data/human_made_clean.csv\"\n",
    "AI_PATH    = \"./Data/AI_made_clean.csv\"\n",
    "OUT_PATH   = \"./Data/all.csv\"\n",
    "\n",
    "# =========================\n",
    "# 1) CSV 로드\n",
    "# =========================\n",
    "human = pd.read_csv(HUMAN_PATH, encoding=\"utf-8\")  # utf-8로 저장했으면 utf-8로 바꿔도 됨\n",
    "ai    = pd.read_csv(AI_PATH, encoding=\"utf-8\")\n",
    "\n",
    "# 컬럼 체크 (id, text, label 존재해야 함)\n",
    "need_cols = {\"id\", \"text\", \"label\"}\n",
    "if not need_cols.issubset(human.columns) or not need_cols.issubset(ai.columns):\n",
    "    raise ValueError(f\"CSV 컬럼 확인 필요: 반드시 {need_cols} 포함해야 함\")\n",
    "\n",
    "# =========================\n",
    "# 2) 라벨 규칙 통일\n",
    "#   목표: 0=Human, 1=AI\n",
    "#   현재 파일은 반대로 들어가 있어서 뒤집어줌\n",
    "# =========================\n",
    "human[\"label\"] = 0  # 사람 데이터는 무조건 0\n",
    "ai[\"label\"] = 1     # AI 데이터는 무조건 1\n",
    "\n",
    "# (선택) 출처 컬럼 추가하면 나중에 확인하기 좋음\n",
    "human[\"source\"] = \"human\"\n",
    "ai[\"source\"] = \"ai\"\n",
    "\n",
    "# =========================\n",
    "# 3) 텍스트 정리 (최소만)\n",
    "# =========================\n",
    "def clean_text(s):\n",
    "    s = str(s)\n",
    "    s = s.replace(\"\\ufeff\", \"\")  # BOM 제거\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "human[\"text\"] = human[\"text\"].apply(clean_text)\n",
    "ai[\"text\"] = ai[\"text\"].apply(clean_text)\n",
    "\n",
    "# 빈 텍스트 제거\n",
    "human = human[human[\"text\"] != \"\"]\n",
    "ai = ai[ai[\"text\"] != \"\"]\n",
    "\n",
    "# (선택) 너무 짧은 텍스트 제거 (예: 20자 미만)\n",
    "MIN_CHARS = 20\n",
    "human = human[human[\"text\"].str.len() >= MIN_CHARS]\n",
    "ai = ai[ai[\"text\"].str.len() >= MIN_CHARS]\n",
    "\n",
    "# =========================\n",
    "# 4) 병합 + 중복 제거\n",
    "# =========================\n",
    "all_df = pd.concat([human, ai], ignore_index=True)\n",
    "\n",
    "# 텍스트 완전 동일 중복 제거(중요)\n",
    "all_df = all_df.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "# id가 겹칠 수 있으니 새 id 부여(권장)\n",
    "all_df.insert(0, \"new_id\", range(1, len(all_df) + 1))\n",
    "\n",
    "# =========================\n",
    "# 5) 저장\n",
    "# =========================\n",
    "all_df.to_csv(OUT_PATH, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ 저장 완료:\", OUT_PATH)\n",
    "print(\"전체 샘플 수:\", len(all_df))\n",
    "print(\"라벨 분포:\\n\", all_df[\"label\"].value_counts())\n",
    "print(\"샘플 컬럼:\", list(all_df.columns))\n",
    "print(all_df.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
